{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "import csv\n",
    "import json\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "import sys\n",
    "from pyspark import SparkContext \n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext('local[*]', 'task')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"hw6_clustering.txt\"\n",
    "n_cluster = 10\n",
    "output_file = \"output.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split_5():\n",
    "    rand_num = random.random()\n",
    "    if rand_num<0.2:\n",
    "        return 0\n",
    "    elif rand_num<0.4:\n",
    "        return 1\n",
    "    elif rand_num<0.6:\n",
    "        return 2\n",
    "    elif rand_num<0.8:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "    \n",
    "def Mahalanobis_Distance(x, N, SUM, SUMSQ):\n",
    "\n",
    "    d_to_cluster = dict()   \n",
    "    for cluster_idx in range(len(SUM)):\n",
    "        tmp = 0\n",
    "        for idx in range(len(x)-2):\n",
    "            c_i = SUM[cluster_idx][1][idx]/N[cluster_idx][1]\n",
    "            sigma_i = ((SUMSQ[cluster_idx][1][idx]/N[cluster_idx][1] - (SUM[cluster_idx][1][idx]/N[cluster_idx][1])**2) **0.5)\n",
    "            tmp += ((x[idx+2] - c_i) / sigma_i )**2\n",
    "        d = tmp**0.5\n",
    "        d_to_cluster[SUM[cluster_idx][0]] = d\n",
    "        \n",
    "    return d_to_cluster\n",
    "\n",
    "def Mahalanobis_Distance_btw_two_clusters(cluster_id, N, SUM, SUMSQ, dim):\n",
    "    d_to_cluster = dict()\n",
    "    c_n = dict(N)[cluster_id]\n",
    "    c_sum = dict(SUM)[cluster_id]\n",
    "    c_sumsq = dict(SUMSQ)[cluster_id]\n",
    "    \n",
    "    c_centroid = [dict(SUM)[cluster_id][idx]/dict(N)[cluster_id] for idx in range(dim)]\n",
    "    c_sigma = [((dict(SUMSQ)[cluster_id][idx]/dict(N)[cluster_id] - (dict(SUM)[cluster_id][idx]/dict(N)[cluster_id])**2)**0.5) for idx in range(dim)]\n",
    "    for cluster_idx in range(len(SUM)):\n",
    "        tmp = 0\n",
    "        for idx in range(dim):\n",
    "            c_i = SUM[cluster_idx][1][idx]/N[cluster_idx][1]\n",
    "            sigma_i = ((SUMSQ[cluster_idx][1][idx]/N[cluster_idx][1] - (SUM[cluster_idx][1][idx]/N[cluster_idx][1])**2) **0.5)\n",
    "            tmp += ((c_centroid[idx] - c_i)**2)/ (c_sigma[idx]*sigma_i) \n",
    "        d = tmp**0.5\n",
    "        d_to_cluster[SUM[cluster_idx][0]] = d\n",
    "        \n",
    "    return d_to_cluster\n",
    "\n",
    "def Mahalanobis_Distance_btw_CS_DS(cluster_id, N, SUM, SUMSQ, dim, N_CS, SUM_CS, SUMSQ_CS):\n",
    "    d_to_cluster = dict()\n",
    "    c_n = dict(N_CS)[cluster_id]\n",
    "    c_sum = dict(SUM_CS)[cluster_id]\n",
    "    c_sumsq = dict(SUMSQ_CS)[cluster_id]\n",
    "    \n",
    "    c_centroid = [dict(SUM_CS)[cluster_id][idx]/dict(N_CS)[cluster_id] for idx in range(dim)]\n",
    "    c_sigma = [((dict(SUMSQ_CS)[cluster_id][idx]/dict(N_CS)[cluster_id] - (dict(SUM_CS)[cluster_id][idx]/dict(N_CS)[cluster_id])**2)**0.5) for idx in range(dim)]\n",
    "    for cluster_idx in range(len(SUM)):\n",
    "        tmp = 0\n",
    "        for idx in range(dim):\n",
    "            c_i = SUM[cluster_idx][1][idx]/N[cluster_idx][1]\n",
    "            sigma_i = ((SUMSQ[cluster_idx][1][idx]/N[cluster_idx][1] - (SUM[cluster_idx][1][idx]/N[cluster_idx][1])**2) **0.5)\n",
    "            tmp += ((c_centroid[idx] - c_i)**2)/ (c_sigma[idx]*sigma_i) \n",
    "        d = tmp**0.5\n",
    "        d_to_cluster[SUM[cluster_idx][0]] = d\n",
    "        \n",
    "    return d_to_cluster\n",
    "\n",
    "def N_SUM_SSQ(CS):\n",
    "    N_CS = []\n",
    "    SUM_CS = []\n",
    "    SUMSQ_CS = []\n",
    "    for key in CS:\n",
    "        rows = CS[key]\n",
    "        num = 0\n",
    "        s = [0 for i in range(len(rows[0])-2)]\n",
    "        ssq = [0 for i in range(len(rows[0])-2)]\n",
    "        for row in rows:\n",
    "            num+=1\n",
    "            for i in range(len(rows[0])-2):\n",
    "                s[i]+=row[i+2]\n",
    "                ssq[i]+=row[i+2]**2\n",
    "        N_CS.append((key, num))\n",
    "        SUM_CS.append((key, s))\n",
    "        SUMSQ_CS.append((key, ssq))\n",
    "    return N_CS, SUM_CS, SUMSQ_CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_round :  64619\n",
      "Duration :  53.7646861076355\n",
      "The intermediate results:\n",
      "Round 1: 64601 , 0 , 0 , 18\n",
      "Duration :  54.52936601638794\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    \n",
    "    t = time.time()\n",
    "    n = 30\n",
    "    \n",
    "    ## RDDs\n",
    "    textRDD = sc.textFile(input_file, n)\n",
    "    \n",
    "    # Step 1. Load 20% of the data randomly.\n",
    "    random_data = textRDD\\\n",
    "        .map(lambda x : [float(feature) for feature in x.split(\",\")])\\\n",
    "        .map(lambda x : (x,random_split_5()))\\\n",
    "        .cache()\n",
    "             \n",
    "    random_data_0 = random_data.filter(lambda x : x[1] == 0).map(lambda x : x[0])\n",
    "    dim = len(random_data_0.take(1)[0])-2\n",
    "    print(\"num_round : \" , len(random_data_0.collect()))\n",
    "    \n",
    "\n",
    "    # Step 2. Run K-Means (e.g., from sklearn) with a large K (e.g., 5 times of the number of the input clusters) on the data in memory using the Euclidean distance as the similarity measurement.\n",
    "    \n",
    "    collected_data = random_data_0.collect()\n",
    "    large_K = n_cluster * 20\n",
    "    kmeans = KMeans(n_clusters=large_K, random_state=0).fit([row[2:] for row in collected_data])## 0 : id, 1 : label\n",
    "  \n",
    "\n",
    "  \n",
    "    \n",
    "    # Step 3. In the K-Means result from Step 2, move all the clusters that contain only one point to RS (outliers).\n",
    "    \n",
    "    RS = []\n",
    "    RS_labels = sc.parallelize(kmeans.labels_, n)\\\n",
    "        .map(lambda x : (x,1))\\\n",
    "        .reduceByKey(lambda a,b : a+b)\\\n",
    "        .filter(lambda x : x[1] == 1)\\\n",
    "        .map(lambda x : x[0]).collect()\n",
    "    for row, label in zip(collected_data, kmeans.labels_):\n",
    "        if label in RS_labels:\n",
    "            RS.append(row)\n",
    "           \n",
    "\n",
    " \n",
    "    # Step 4. Run K-Means again to cluster the rest of the data points with K = the number of input clusters.\n",
    "    \n",
    "    collected_data = [row for row in collected_data if row not in RS]\n",
    "    kmeans = KMeans(n_clusters=n_cluster, random_state=0).fit([row[2:] for row in collected_data])\n",
    "    result = dict()\n",
    "    for row, label in zip(collected_data, kmeans.labels_):\n",
    "        result[int(row[0])] = label\n",
    "        \n",
    "\n",
    "   \n",
    "\n",
    " \n",
    "    # Step 5. Use the K-Means result from Step 4 to generate the DS clusters (i.e., discard their points and generate statistics).\n",
    "    c = sc.parallelize(collected_data, n)\\\n",
    "        .map(lambda x : x[2:])\\\n",
    "        .map(lambda x : (kmeans.predict([x])[0], x)).cache() ## [label, [a,b,c,d,e]], ....\n",
    "    N = c.map(lambda x : (x[0],1)).reduceByKey(lambda a,b : a+b).collect()\n",
    "    SUM = c.reduceByKey(lambda a,b : [a[i]+b[i] for i in range(len(a))]).collect()\n",
    "    SUMSQ = c.map(lambda x : (x[0], [feature**2 for feature in x[1]]))\\\n",
    "        .reduceByKey(lambda a,b : [a[i]+b[i] for i in range(len(a))]).collect()\n",
    "    \n",
    "\n",
    "    print(\"Duration : \", time.time()-t)\n",
    "\n",
    "    # The initialization of DS has finished, so far, you have K numbers of DS clusters (from Step 5) and some numbers of RS (from Step 3).\n",
    "    # Step 6. Run K-Means on the points in the RS with a large K (e.g., 5 times of the number of the input clusters) to generate CS (clusters with more than one points) and RS (clusters with only one point).\n",
    "    CS = dict()\n",
    "    try:\n",
    "        kmeans = KMeans(n_clusters=n_cluster*2, random_state=0).fit([row[2:] for row in RS])## 0 : id, 1 : label\n",
    "    except:\n",
    "        kmeans = KMeans(n_clusters=len(RS), random_state=0).fit([row[2:] for row in RS])\n",
    "    RS_new = []\n",
    "    RS_labels = sc.parallelize(kmeans.labels_, n)\\\n",
    "        .map(lambda x : (x,1))\\\n",
    "        .reduceByKey(lambda a,b : a+b)\\\n",
    "        .filter(lambda x : x[1] == 1)\\\n",
    "        .map(lambda x : x[0]).collect()\n",
    "    CS_count = 0\n",
    "    RS_count = 0\n",
    "    for row, label in zip(RS, kmeans.labels_):\n",
    "        if label in RS_labels:\n",
    "            RS_count+=1\n",
    "            RS_new.append(row)\n",
    "        if label not in RS_labels:\n",
    "            CS_count+=1\n",
    "            CS[label + Round*10000] = CS.get(label + Round*10000, []) + [row]\n",
    "    #####\n",
    "    N_CS, SUM_CS, SUMSQ_CS = N_SUM_SSQ(CS)\n",
    "\n",
    "            \n",
    "    print(\"The intermediate results:\")\n",
    "    ## number of DS points, number of CS set, number of CS points, number of RS points\n",
    "    print(\"Round {}:\".format(1), sum([cluster[1] for cluster in N]),\",\",len(CS), \",\" , CS_count, \",\", RS_count)\n",
    "            \n",
    "    print(\"Duration : \", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_round :  64210\n",
      "num_res 70 :  128829\n",
      "RES : 128790\n",
      "N_CS : 0\n",
      "RS : 39\n",
      "num_CS :  0\n",
      "#######\n",
      "num_res 94:  128829\n",
      "RES : 128790\n",
      "N_CS : 32\n",
      "RS : 7\n",
      "num_CS :  32\n",
      "#######\n",
      "Round 2: 128790 , 13 , 32 , 7\n",
      "num_res :  128829\n",
      "num_round :  64348\n",
      "num_res 70 :  193177\n",
      "RES : 193118\n",
      "N_CS : 33\n",
      "RS : 26\n",
      "num_CS :  33\n",
      "#######\n",
      "num_res 94:  193177\n",
      "RES : 193118\n",
      "N_CS : 45\n",
      "RS : 14\n",
      "num_CS :  45\n",
      "#######\n",
      "Round 3: 193118 , 14 , 45 , 14\n",
      "num_res :  193177\n",
      "num_round :  64772\n",
      "num_res 70 :  257949\n",
      "RES : 257872\n",
      "N_CS : 53\n",
      "RS : 24\n",
      "num_CS :  53\n",
      "#######\n",
      "num_res 94:  257949\n",
      "RES : 257872\n",
      "N_CS : 60\n",
      "RS : 17\n",
      "num_CS :  60\n",
      "#######\n",
      "Round 4: 257872 , 17 , 60 , 17\n",
      "num_res :  257949\n",
      "num_round :  64363\n",
      "num_res 70 :  322312\n",
      "RES : 322210\n",
      "N_CS : 76\n",
      "RS : 26\n",
      "num_CS :  76\n",
      "#######\n",
      "num_res 94:  322312\n",
      "RES : 322210\n",
      "N_CS : 87\n",
      "RS : 15\n",
      "num_CS :  87\n",
      "#######\n",
      "Round 5: 322210 , 21 , 87 , 15\n",
      "num_res :  322312\n",
      "Duration :  110.84398293495178\n"
     ]
    }
   ],
   "source": [
    "    for Round in [2,3,4,5]:\n",
    "#     Round = 1\n",
    "        # Step 7. Load another 20% of the data randomly.\n",
    "        random_data_round = random_data.filter(lambda x : x[1] == Round-1).map(lambda x : x[0])\n",
    "        print(\"num_round : \" , len(random_data_round.collect()))\n",
    "\n",
    "        # Step 8. For the new points, compare them to each of the DS using the Mahalanobis Distance and assign\n",
    "        # them to the nearest DSclusters if the distance is <2 root ð‘‘.\n",
    "        #d = root(sigma( (x - SUM/N)/((SUMSQ/N - (SUM/N)^2) **0.5) ))\n",
    "\n",
    "        base = 2 * ((10**0.5))\n",
    "        filtered_data = random_data_round\\\n",
    "            .map(lambda x : [x,Mahalanobis_Distance(x, N, SUM, SUMSQ)])\\\n",
    "            .map(lambda x :  [x[0],min(x[1].items(), key = lambda y : y[1])])\\\n",
    "            .map(lambda x : [x[0], x[1][0]] if x[1][1]<base else [x[0], \"not DS\"] ).cache()\n",
    "        for row, label in filtered_data.collect():\n",
    "            if label != \"not DS\":\n",
    "                result[int(row[0])] = label\n",
    "        N_new = filtered_data.map(lambda x : (x[1], 1)).reduceByKey(lambda a,b : a+b).collect()\n",
    "        SUM_new = filtered_data.map(lambda x: (x[1], x[0][2:]))\\\n",
    "                                    .reduceByKey(lambda a,b : [a[i]+b[i] for i in range(len(a))]).collect()\n",
    "        SUMSQ_new = filtered_data.map(lambda x : (x[1], [feature**2 for feature in x[0][2:]]))\\\n",
    "            .reduceByKey(lambda a,b : [a[i]+b[i] for i in range(len(a))]).collect()\n",
    "\n",
    "        tmp_N_dict = dict()\n",
    "        tmp_SUM_dict = dict()\n",
    "        tmp_SUMSQ_dict = dict()\n",
    "        for key in dict(N).keys():\n",
    "            tmp_N_dict[key] = dict(N)[key] + dict(N_new)[key]\n",
    "            tmp_SUM_dict[key] = [dict(SUM)[key][i] + dict(SUM_new)[key][i] for i in range(dim)]\n",
    "            tmp_SUMSQ_dict[key] = [dict(SUMSQ)[key][i] + dict(SUMSQ_new)[key][i] for i in range(dim)]\n",
    "\n",
    "        N = list(tmp_N_dict.items())\n",
    "        SUM = list(tmp_SUM_dict.items())\n",
    "        SUMSQ = list(tmp_SUMSQ_dict.items())\n",
    "\n",
    "\n",
    "        # Step 9. For the new points that are not assigned to DS clusters, using the Mahalanobis Distance and\n",
    "        # assign the points to the nearest CS clusters if the distance is <2 root ð‘‘\n",
    "        NOT_DS = filtered_data.filter(lambda x : x[1] == \"not DS\").map(lambda x : x[0])\\\n",
    "            .map(lambda x : [x,Mahalanobis_Distance(x, N_CS, SUM_CS, SUMSQ_CS)])\\\n",
    "            .map(lambda x :  [x[0],min(x[1].items(), key = lambda y : y[1])] if len(N_CS)>0 else [x[0], (0,base+1)])\\\n",
    "            .map(lambda x : [x[0], x[1][0]] if x[1][1]<base else [x[0], \"not CS\"] ).cache()\n",
    "        \n",
    "        ## add rows to CS\n",
    "        for row in NOT_DS.collect():\n",
    "            if row[1] != \"not CS\":\n",
    "                CS[row[1]] = CS.get(row[1],[]) + [row[0]]\n",
    "\n",
    "        N_CS_new = NOT_DS.map(lambda x : (x[1], 1)).reduceByKey(lambda a,b : a+b).collect()\n",
    "        SUM_CS_new = NOT_DS.map(lambda x: (x[1], x[0][2:]))\\\n",
    "                                    .reduceByKey(lambda a,b : [a[i]+b[i] for i in range(len(a))]).collect()\n",
    "        SUMSQ_CS_new = NOT_DS.map(lambda x : (x[1], [feature**2 for feature in x[0][2:]]))\\\n",
    "            .reduceByKey(lambda a,b : [a[i]+b[i] for i in range(len(a))]).collect()\n",
    "\n",
    "        tmp_N_dict = dict()\n",
    "        tmp_SUM_dict = dict()\n",
    "        tmp_SUMSQ_dict = dict()\n",
    "        for key in dict(N_CS).keys():\n",
    "            tmp_N_dict[key] = dict(N_CS)[key] + dict(N_CS_new).get(key, 0)\n",
    "            tmp_SUM_dict[key] = [dict(SUM_CS)[key][i] + dict(SUM_CS_new).get(key, [0 for idx in range(dim)])[i] for i in range(dim)]\n",
    "            tmp_SUMSQ_dict[key] = [dict(SUMSQ_CS)[key][i] + dict(SUMSQ_CS_new).get(key, [0 for idx in range(dim)])[i] for i in range(dim)]\n",
    "\n",
    "        N_CS = list(tmp_N_dict.items())\n",
    "        SUM_CS = list(tmp_SUM_dict.items())\n",
    "        SUMSQ_CS = list(tmp_SUMSQ_dict.items())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Step 10. For the new points that are not assigned to a DS cluster or a CS cluster, assign them to RS.\n",
    "        NOT_CS = NOT_DS.filter(lambda x : x[1] == \"not CS\").map(lambda x : x[0]).collect()\n",
    "        RS = RS + NOT_CS\n",
    "        \n",
    "        print(\"num_res 70 : \",  len(result)+sum(list(dict(N_CS).values()))+len(RS))\n",
    "        print(\"RES :\", len(result))\n",
    "        print(\"N_CS :\",sum(list(dict(N_CS).values())))\n",
    "        print(\"RS :\", len(RS))\n",
    "        ##CSê°œìˆ˜\n",
    "        count = 0\n",
    "        for key in CS:\n",
    "            count += len(CS[key])\n",
    "        print(\"num_CS : \",count)\n",
    "        print(\"#######\")  \n",
    "\n",
    "\n",
    "        # Step 11. Run K-Means on the RS with a large K (e.g., 5 times of the number of the input clusters) to generate CS (clusters with more than one points) and RS (clusters with only one point).\n",
    "        try:\n",
    "            kmeans = KMeans(n_clusters=n_cluster*2, random_state=0).fit([row[2:] for row in RS])## 0 : id, 1 : label\n",
    "        except:\n",
    "            kmeans = KMeans(n_clusters=len(RS), random_state=0).fit([row[2:] for row in RS])\n",
    "\n",
    "        RS_labels = sc.parallelize(kmeans.labels_, n)\\\n",
    "            .map(lambda x : (x,1))\\\n",
    "            .reduceByKey(lambda a,b : a+b)\\\n",
    "            .filter(lambda x : x[1] == 1)\\\n",
    "            .map(lambda x : x[0]).collect()\n",
    "        CS_count = 0\n",
    "        RS_count = 0\n",
    "            \n",
    "        rm_row = []\n",
    "        for row, label in zip(RS, kmeans.labels_):\n",
    "            if label in RS_labels:\n",
    "                RS_count+=1\n",
    "\n",
    "            if label not in RS_labels:\n",
    "                CS_count+=1\n",
    "                CS[label + Round*10000] = CS.get(label + Round*10000, []) + [row]\n",
    "                rm_row.append(row)\n",
    "\n",
    "        for row in rm_row:\n",
    "            RS.remove(row)\n",
    "                    \n",
    "        N_CS, SUM_CS, SUMSQ_CS = N_SUM_SSQ(CS)\n",
    "        print(\"num_res 94: \",  len(result)+sum(list(dict(N_CS).values()))+len(RS))\n",
    "        print(\"RES :\", len(result))\n",
    "        print(\"N_CS :\",sum(list(dict(N_CS).values())))\n",
    "        print(\"RS :\", len(RS))\n",
    "\n",
    "        ##CSê°œìˆ˜\n",
    "        count = 0\n",
    "        for key in CS:\n",
    "            count += len(CS[key])\n",
    "        print(\"num_CS : \",count)\n",
    "        print(\"#######\")  \n",
    "\n",
    "        # Step 12.Merge CS clusters that have a Mahalanobis Distance <2 root ð‘‘.\n",
    "        New_N_CS_len = 10*10\n",
    "        while len(N_CS) != New_N_CS_len and New_N_CS_len>1:\n",
    "            N_CS, SUM_CS, SUMSQ_CS = N_SUM_SSQ(CS)\n",
    "            centroids_CS = dict()\n",
    "            for cluster_id in CS:\n",
    "        #         print(dict(N_CS)[cluster_id])\n",
    "                tmp = []\n",
    "                for idx in range(dim):\n",
    "                    tmp.append(dict(SUM_CS)[cluster_id][idx]/dict(N_CS)[cluster_id])\n",
    "                centroids_CS[cluster_id] = tmp\n",
    "\n",
    "            tmp = 0\n",
    "            for cluster_id in centroids_CS:\n",
    "                if tmp == 0:\n",
    "                    m_dist = Mahalanobis_Distance_btw_two_clusters(cluster_id, N_CS, SUM_CS, SUMSQ_CS, dim)\n",
    "                    del m_dist[cluster_id]\n",
    "                    closest_cluster,mindist = min(m_dist.items(), key = lambda y: y[1])\n",
    "                    if mindist < base:\n",
    "                        tmp+=1\n",
    "#                         print(\"c id : \" ,cluster_id)\n",
    "#                         print(\"d id : \", closest_cluster)\n",
    "                        CS[cluster_id] = CS[cluster_id] + CS[closest_cluster]\n",
    "                        del CS[closest_cluster]\n",
    "            New_N_CS_len = len(CS)\n",
    "            \n",
    "        N_CS, SUM_CS, SUMSQ_CS = N_SUM_SSQ(CS)\n",
    "\n",
    "        ## Step 13. merge CS with DS that have a Mahalanobis Distance <2 root d\n",
    "        if Round == 5:\n",
    "            del_cluster = []\n",
    "            for cluster in CS:\n",
    "                dist_to_DS = Mahalanobis_Distance_btw_CS_DS(cluster, N, SUM, SUMSQ, dim, N_CS, SUM_CS, SUMSQ_CS)\n",
    "                closest_DS, mindist = min(dist_to_DS.items(), key = lambda y: y[1])\n",
    "                \n",
    "                if mindist < base:\n",
    "                    del_cluster.append(cluster)\n",
    "                    print(cluster)\n",
    "                    print(closest_DS, mindist)\n",
    "                    tmp_N_dict = dict(N)\n",
    "                    tmp_SUM_dict = dict(SUM)\n",
    "                    tmp_SUMSQ_dict = dict(SUMSQ)\n",
    "                    tmp_N_dict[closest_DS] = tmp_N_dict[closest_DS] + dict(N_CS)[cluster]\n",
    "                    tmp_SUM_dict[closest_DS] = tmp_SUM_dict[closest_DS] + dict(SUM_CS)[cluster]\n",
    "                    tmp_SUMSQ_dict[closest_DS] = tmp_SUMSQ_dict[closest_DS] + dict(SUMSQ_CS)[cluster]\n",
    "                    \n",
    "                    N = list(tmp_N_dict.items())\n",
    "                    SUM = list(tmp_SUM_dict.items())\n",
    "                    SUMSQ = list(tmp_SUMSQ_dict.items())\n",
    "                    \n",
    "                    for row in CS[cluster]:\n",
    "                        result[int(row[0])] = closest_DS\n",
    "                        \n",
    "            for cluster in del_cluster:\n",
    "                del CS[cluster]\n",
    "\n",
    "        N_CS, SUM_CS, SUMSQ_CS = N_SUM_SSQ(CS)\n",
    "        print(\"Round {}:\".format(Round), sum([cluster[1] for cluster in N]),\",\",len(CS), \",\" , sum(list(dict(N_CS).values())), \",\", len(RS))\n",
    "        print(\"num_res : \",  len(result)+sum(list(dict(N_CS).values()))+len(RS))\n",
    "            \n",
    "    \n",
    "    \n",
    "    print(\"Duration : \", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 17, 18,  0, 11,  3,  7, 13, 10,  1, 14, 16,  5, 14,  6,  1,  9,\n",
       "        5,  6, 13,  7, 19,  3, 12,  0,  7,  8,  1, 15, 10,  0,  6,  5,  1,\n",
       "        5,  3,  4,  0,  2, 16,  4], dtype=int32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-101"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(result.keys()))-322312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NOT_CS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12049.0,\n",
       "  -1.0,\n",
       "  926.3919413069962,\n",
       "  636.1659751280349,\n",
       "  717.0570669250868,\n",
       "  897.9535339242541,\n",
       "  788.3146958601612,\n",
       "  672.7337145809307,\n",
       "  590.6979270459199,\n",
       "  896.0154170747182,\n",
       "  887.4563722204036,\n",
       "  851.8592279550278],\n",
       " [13479.0,\n",
       "  -1.0,\n",
       "  -818.6927782739829,\n",
       "  -1075.8951994388685,\n",
       "  -706.4931980353986,\n",
       "  -700.733838726702,\n",
       "  -1049.6729554511426,\n",
       "  -584.0728398351557,\n",
       "  -729.0445172010881,\n",
       "  -774.6470081493524,\n",
       "  -826.1585850768568,\n",
       "  -609.9020514578608],\n",
       " [21290.0,\n",
       "  -1.0,\n",
       "  -565.980483263564,\n",
       "  -417.85493100932075,\n",
       "  -774.7991528975615,\n",
       "  -513.2833733707218,\n",
       "  -783.3612920905719,\n",
       "  -772.6063431119846,\n",
       "  -451.37301248632826,\n",
       "  -684.2999276194215,\n",
       "  -795.5561021575325,\n",
       "  -592.5500281652643],\n",
       " [25402.0,\n",
       "  -1.0,\n",
       "  744.214368728761,\n",
       "  604.4112727302727,\n",
       "  777.2291258205669,\n",
       "  786.831530276389,\n",
       "  644.2850761775976,\n",
       "  793.0963810998428,\n",
       "  889.8786795470905,\n",
       "  670.2389822695048,\n",
       "  605.2920472429176,\n",
       "  952.3381265946174],\n",
       " [44522.0,\n",
       "  -1.0,\n",
       "  727.9210742312863,\n",
       "  855.8532659456439,\n",
       "  645.3926646449108,\n",
       "  549.2529438142071,\n",
       "  882.5475231322887,\n",
       "  822.3497185455697,\n",
       "  680.5010772147245,\n",
       "  941.4391835684437,\n",
       "  786.365706185587,\n",
       "  511.36150889816304],\n",
       " [52454.0,\n",
       "  -1.0,\n",
       "  511.811174895178,\n",
       "  484.51001851329863,\n",
       "  725.7352627508951,\n",
       "  474.04105776360893,\n",
       "  760.5702044206341,\n",
       "  484.35502650116024,\n",
       "  580.6851085561406,\n",
       "  743.0675772536231,\n",
       "  716.070229415848,\n",
       "  902.6725941756604],\n",
       " [60843.0,\n",
       "  -1.0,\n",
       "  -894.8497440540086,\n",
       "  -1031.799671389363,\n",
       "  -846.6188294514275,\n",
       "  -998.7212368338176,\n",
       "  -938.7117818874899,\n",
       "  -557.2894533619038,\n",
       "  -858.6515220867311,\n",
       "  -1027.9006742755382,\n",
       "  -523.6613091123476,\n",
       "  -946.0033555328885],\n",
       " [62431.0,\n",
       "  -1.0,\n",
       "  -776.9683428249505,\n",
       "  -642.8055185403732,\n",
       "  -447.95082777977484,\n",
       "  -405.3705866021187,\n",
       "  -686.1209278817439,\n",
       "  -423.1508267252963,\n",
       "  -491.7973318288226,\n",
       "  -785.0833981216193,\n",
       "  -771.3903062612937,\n",
       "  -591.9029389342709],\n",
       " [65075.0,\n",
       "  -1.0,\n",
       "  775.2498064097416,\n",
       "  510.097251086044,\n",
       "  761.5793882636248,\n",
       "  427.69454488718947,\n",
       "  442.93808501029207,\n",
       "  462.4201792691387,\n",
       "  442.8534064683475,\n",
       "  489.80805653355014,\n",
       "  708.5981047013297,\n",
       "  505.5279622931201],\n",
       " [86203.0,\n",
       "  -1.0,\n",
       "  736.6671685149723,\n",
       "  632.2933762534533,\n",
       "  549.7437416292418,\n",
       "  715.7533825832807,\n",
       "  497.9367332545275,\n",
       "  748.4513858955113,\n",
       "  723.9742104744856,\n",
       "  806.6242460687245,\n",
       "  757.7714614149843,\n",
       "  599.257637877502],\n",
       " [90431.0,\n",
       "  -1.0,\n",
       "  633.935278461237,\n",
       "  827.3916656957927,\n",
       "  787.731869223562,\n",
       "  713.225653725925,\n",
       "  883.2224037489441,\n",
       "  812.5208518305931,\n",
       "  742.7999339388975,\n",
       "  792.9131072654568,\n",
       "  633.8048379858103,\n",
       "  596.7692107130416],\n",
       " [97657.0,\n",
       "  -1.0,\n",
       "  889.2768757955073,\n",
       "  508.87711966142626,\n",
       "  719.9876256538538,\n",
       "  531.5470421106006,\n",
       "  800.0688416992673,\n",
       "  615.2466176389175,\n",
       "  724.091800228417,\n",
       "  683.6556162907938,\n",
       "  652.5215255503933,\n",
       "  489.0890005196892],\n",
       " [99187.0,\n",
       "  -1.0,\n",
       "  -817.3069420207094,\n",
       "  -685.0529579395145,\n",
       "  -630.4636364710186,\n",
       "  -676.8513575340464,\n",
       "  -801.3641939305983,\n",
       "  -807.472157890813,\n",
       "  -839.6769380013641,\n",
       "  -692.0331354009566,\n",
       "  -900.5367628388091,\n",
       "  -678.824990179474],\n",
       " [195423.0,\n",
       "  -1.0,\n",
       "  -695.6201483143886,\n",
       "  -577.7196507892979,\n",
       "  -477.40988056275205,\n",
       "  -765.4232475499743,\n",
       "  -788.5337922901243,\n",
       "  -589.1057567144886,\n",
       "  -558.4426487725939,\n",
       "  -743.3026870414506,\n",
       "  -611.4920573270982,\n",
       "  -429.69269099083033],\n",
       " [222969.0,\n",
       "  -1.0,\n",
       "  -485.89133826087067,\n",
       "  -670.5859250888086,\n",
       "  -550.9421668632758,\n",
       "  -567.1711794772747,\n",
       "  -546.4709511208202,\n",
       "  -604.3858753872092,\n",
       "  -894.8202080072522,\n",
       "  -725.0173413614853,\n",
       "  -680.6530444800469,\n",
       "  -818.8712076496718],\n",
       " [250911.0,\n",
       "  -1.0,\n",
       "  -687.0311337759445,\n",
       "  -793.7783982641251,\n",
       "  -784.7435918754798,\n",
       "  -512.9166234289597,\n",
       "  -683.8063257342493,\n",
       "  -878.7756588039852,\n",
       "  -617.1287555587859,\n",
       "  -567.3696161105211,\n",
       "  -669.0103399313994,\n",
       "  -698.8231507506875],\n",
       " [264082.0,\n",
       "  -1.0,\n",
       "  771.04188778652,\n",
       "  1130.2268130985717,\n",
       "  979.0721013847635,\n",
       "  756.7155603166195,\n",
       "  643.1857780779842,\n",
       "  746.3619900536569,\n",
       "  1152.366459716758,\n",
       "  1037.5196831652088,\n",
       "  899.5757374080368,\n",
       "  1041.277909200942],\n",
       " [268900.0,\n",
       "  -1.0,\n",
       "  800.0999806424616,\n",
       "  787.5578602510054,\n",
       "  983.4178753018772,\n",
       "  735.1896001585063,\n",
       "  838.9408455826375,\n",
       "  654.1360978779907,\n",
       "  652.1524074585402,\n",
       "  931.9031880807077,\n",
       "  821.1136600455026,\n",
       "  654.2413489419945],\n",
       " [281755.0,\n",
       "  7.0,\n",
       "  92.99515471987554,\n",
       "  -91.71780501398307,\n",
       "  99.91152609097567,\n",
       "  103.98132595010108,\n",
       "  -94.14728101098292,\n",
       "  -77.31057051506731,\n",
       "  -78.09141757454732,\n",
       "  -53.70451923521362,\n",
       "  -81.85784697418372,\n",
       "  49.67273964633989],\n",
       " [293977.0,\n",
       "  -1.0,\n",
       "  559.1526435870628,\n",
       "  892.5763779054207,\n",
       "  560.5852234467509,\n",
       "  563.2918328794428,\n",
       "  1092.8743361033812,\n",
       "  633.583437066416,\n",
       "  971.6214554081589,\n",
       "  986.7902001452214,\n",
       "  967.2578505143401,\n",
       "  849.3269797401924],\n",
       " [301050.0,\n",
       "  -1.0,\n",
       "  1079.311336959299,\n",
       "  771.3004533865036,\n",
       "  861.6667698161821,\n",
       "  679.6856930589104,\n",
       "  704.5185825698975,\n",
       "  716.2150208444979,\n",
       "  1067.1498112167126,\n",
       "  1067.6175117076132,\n",
       "  988.6449578343455,\n",
       "  947.4277415678122]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NOT_CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 8, 9, 11, 15, 17, 18, 19]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RS_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([20012, 20000, 20003, 20007, 20013, 20010, 20001, 20014, 20016, 20005, 20006])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in CS:\n",
    "    count+=len(CS[i])\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    with open(output_file, 'w') as file:\n",
    "        file.write(\"The clustering results:\\n\")\n",
    "        for idx, est in enumerate(Estimation):\n",
    "            file.write(str(idx) + \",\" + str(stream_size) + \",\" + str(int(est)))\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12551.0,\n",
       "  9.0,\n",
       "  -136.07054580881638,\n",
       "  -169.10567624774328,\n",
       "  -168.17118290137495,\n",
       "  -142.36092082473812,\n",
       "  -156.34084296633958,\n",
       "  -158.51646939282458,\n",
       "  178.61390504102192,\n",
       "  -196.52132877411378,\n",
       "  182.13353272337093,\n",
       "  157.44492184066425],\n",
       " 'not CS']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " NOT_DS.collect()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ha\n",
      "ha\n",
      "ha\n",
      "ha\n",
      "ha\n",
      "ha\n",
      "ha\n",
      "ha\n",
      "ha\n"
     ]
    }
   ],
   "source": [
    "for row in NOT_DS.collect():\n",
    "    if row[1] != \"not CS\":\n",
    "        CS[row[1]] = CS.get(row[1],[]) + [row]\n",
    "        print(\"ha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([5, 7, 16, 20015, 20000, 20007, 20002, 20003, 20011, 20004, 20010, 20013, 30003, 30006, 30001, 30013, 30012, 30002, 30015, 30004, 30019, 30016, 30009, 30008, 30014, 30010, 30011, 30000, 40000, 40005, 40007, 40017, 40019, 40001, 40018, 40010, 40013, 40002, 40014, 40015, 40011, 40003, 40006, 40004, 40009, 50009, 50003, 50016, 50000, 50010, 50001, 50005, 50013, 50018, 50014, 50019, 50015, 50006, 50007, 50012, 50011, 50002, 50008])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 9. For the new points that are not assigned to DS clusters, using the Mahalanobis Distance and\n",
    "        # assign the points to the nearest CS clusters if the distance is <2 root ð‘‘\n",
    "        NOT_DS = filtered_data.filter(lambda x : x[1] == \"not DS\").map(lambda x : x[0])\\\n",
    "            .map(lambda x : [x,Mahalanobis_Distance(x, N_CS, SUM_CS, SUMSQ_CS)])\\\n",
    "            .map(lambda x :  [x[0],min(x[1].items(), key = lambda y : y[1])] if len(N_CS)>0 else [x[0], (0,base+1)])\\\n",
    "            .map(lambda x : [x[0], x[1][0]] if x[1][1]<base else [x[0], \"not CS\"] ).cache()\n",
    "\n",
    "        N_CS_new = NOT_DS.map(lambda x : (x[1], 1)).reduceByKey(lambda a,b : a+b).collect()\n",
    "        SUM_CS_new = NOT_DS.map(lambda x: (x[1], x[0][2:]))\\\n",
    "                                    .reduceByKey(lambda a,b : [a[i]+b[i] for i in range(len(a))]).collect()\n",
    "        SUMSQ_CS_new = NOT_DS.map(lambda x : (x[1], [feature**2 for feature in x[0][2:]]))\\\n",
    "            .reduceByKey(lambda a,b : [a[i]+b[i] for i in range(len(a))]).collect()\n",
    "\n",
    "        tmp_N_dict = dict()\n",
    "        tmp_SUM_dict = dict()\n",
    "        tmp_SUMSQ_dict = dict()\n",
    "        for key in dict(N_CS).keys():\n",
    "            tmp_N_dict[key] = dict(N_CS)[key] + dict(N_CS_new).get(key, 0)\n",
    "            tmp_SUM_dict[key] = [dict(SUM_CS)[key][i] + dict(SUM_CS_new).get(key, [0 for idx in range(dim)])[i] for i in range(dim)]\n",
    "            tmp_SUMSQ_dict[key] = [dict(SUMSQ_CS)[key][i] + dict(SUMSQ_CS_new).get(key, [0 for idx in range(dim)])[i] for i in range(dim)]\n",
    "\n",
    "        N_CS = list(tmp_N_dict.items())\n",
    "        SUM_CS = list(tmp_SUM_dict.items())\n",
    "        SUMSQ_CS = list(tmp_SUMSQ_dict.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322209"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([row[1] for row in N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Step 13. merge CS with DS that have a Mahalanobis Distance <2 root d\n",
    "if Round ==4:\n",
    "    for cluster in CS:\n",
    "        dist_to_DS = Mahalanobis_Distance_btw_CS_DS(cluster, N, SUM, SUMSQ, dim, N_CS, SUM_CS, SUMSQ_CS)\n",
    "        closest_DS, mindist = min(dist_to_DS.items(), key = lambda y: y[1])\n",
    "        print(cluster)\n",
    "        print(closest_DS, mindist)\n",
    "        if mindist < base:\n",
    "            tmp_N_dict = dict(N)\n",
    "            tmp_SUM_dict = dict(SUM)\n",
    "            tmp_SUMSQ_dict = dict(SUMSQ)\n",
    "            tmp_N_dict[closest_DS] = tmp_N_dict[closest_DS] + dict(N_CS)[cluster]\n",
    "            tmp_SUM_dict[closest_DS] = tmp_SUM_dict[closest_DS] + dict(SUM_CS)[cluster]\n",
    "            tmp_SUMSQ_dict[closest_DS] = tmp_SUMSQ_dict[closest_DS] + dict(SUMSQ_CS)[cluster]\n",
    "            del CS[cluster]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 6.758848804263444,\n",
       " 1: 11.259920132510954,\n",
       " 2: 46.0291346228439,\n",
       " 3: 27.65114840208466,\n",
       " 4: 29.05665539453182,\n",
       " 5: 25.60691774392599,\n",
       " 6: 29.98678287542144,\n",
       " 7: 17.07722540937219,\n",
       " 8: 9.10432222098056,\n",
       " 9: 8.097573609694457}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_to_DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.324555320336759"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11, 2),\n",
       " (10, 2),\n",
       " (5, 2),\n",
       " (14, 3),\n",
       " (4, 2),\n",
       " (10019, 2),\n",
       " (10001, 4),\n",
       " (10013, 2),\n",
       " (10011, 2),\n",
       " (10004, 3),\n",
       " (10015, 3),\n",
       " (10010, 3),\n",
       " (10005, 3),\n",
       " (10002, 2),\n",
       " (10006, 2),\n",
       " (10000, 5),\n",
       " (10007, 3),\n",
       " (10016, 3),\n",
       " (10008, 2),\n",
       " (20016, 4),\n",
       " (20010, 4),\n",
       " (20004, 3),\n",
       " (20017, 2),\n",
       " (20005, 7),\n",
       " (20008, 6),\n",
       " (20012, 4),\n",
       " (20009, 3),\n",
       " (20018, 3),\n",
       " (20015, 2),\n",
       " (20001, 3),\n",
       " (20003, 3),\n",
       " (20013, 4),\n",
       " (20000, 3),\n",
       " (30008, 3),\n",
       " (30003, 4),\n",
       " (30001, 7),\n",
       " (30011, 5),\n",
       " (30015, 3),\n",
       " (30010, 2),\n",
       " (30005, 6),\n",
       " (30006, 4),\n",
       " (30013, 4),\n",
       " (30007, 2),\n",
       " (30009, 3),\n",
       " (30012, 2),\n",
       " (30004, 4),\n",
       " (30017, 2),\n",
       " (30019, 2),\n",
       " (30014, 2),\n",
       " (30002, 2),\n",
       " (40008, 5),\n",
       " (40003, 5),\n",
       " (40001, 7),\n",
       " (40011, 3),\n",
       " (40009, 2),\n",
       " (40005, 5),\n",
       " (40006, 7),\n",
       " (40012, 4),\n",
       " (40007, 2),\n",
       " (40016, 2),\n",
       " (40004, 6),\n",
       " (40018, 2),\n",
       " (40015, 2),\n",
       " (40002, 4)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Mahalanobis_Distance_btw_CS_DS(cluster_id, N, SUM, SUMSQ, dim, N_CS, SUM_CS, SUMSQ_CS):\n",
    "    d_to_cluster = dict()\n",
    "    c_n = dict(N_CS)[cluster_id]\n",
    "    c_sum = dict(SUM_CS)[cluster_id]\n",
    "    c_sumsq = dict(SUMSQ_CS)[cluster_id]\n",
    "    \n",
    "    c_centroid = [dict(SUM_CS)[cluster_id][idx]/dict(N_CS)[cluster_id] for idx in range(dim)]\n",
    "    c_sigma = [((dict(SUMSQ_CS)[cluster_id][idx]/dict(N_CS)[cluster_id] - (dict(SUM_CS)[cluster_id][idx]/dict(N_CS)[cluster_id])**2)**0.5) for idx in range(dim)]\n",
    "    for cluster_idx in range(len(SUM)):\n",
    "        tmp = 0\n",
    "        for idx in range(dim):\n",
    "            c_i = SUM[cluster_idx][1][idx]/N[cluster_idx][1]\n",
    "            sigma_i = ((SUMSQ[cluster_idx][1][idx]/N[cluster_idx][1] - (SUM[cluster_idx][1][idx]/N[cluster_idx][1])**2) **0.5)\n",
    "            tmp += ((c_centroid[idx] - c_i)**2)/ (c_sigma[idx]*sigma_i) \n",
    "        d = tmp**0.5\n",
    "        d_to_cluster[SUM[cluster_idx][0]] = d\n",
    "        \n",
    "    return d_to_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration :  215.72827696800232\n"
     ]
    }
   ],
   "source": [
    "    print(\"Duration : \", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 160.29740342792525,\n",
       " 1: 213.1414304159653,\n",
       " 2: 194.5434121368717,\n",
       " 3: 176.3158622719533,\n",
       " 4: 137.60815251155995,\n",
       " 5: 194.67216170081252,\n",
       " 6: 209.77281883991662,\n",
       " 7: 144.70845880840218,\n",
       " 8: 149.35168149592036,\n",
       " 9: 136.61521669218715}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mahalanobis_Distance_btw_CS_DS(11, N, SUM, SUMSQ, dim, N_CS, SUM_CS, SUMSQ_CS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([11, 10, 5, 14, 4, 10019, 10001, 10013, 10011, 10004, 10015, 10010, 10005, 10002, 10006, 10000, 10007, 10016, 10008, 20016, 20010, 20004, 20017, 20005, 20008, 20012, 20009, 20018, 20015, 20001, 20003, 20013, 20000, 30008, 30003, 30001, 30011, 30015, 30010, 30005, 30006, 30013, 30007, 30009, 30012, 30004, 30017, 30019, 30014, 30002, 40008, 40003, 40001, 40011, 40009, 40005, 40006, 40012, 40007, 40016, 40004, 40018, 40015, 40002])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    CS = dict()\n",
    "    kmeans = KMeans(n_clusters=n_cluster*2, random_state=0).fit([row[2:] for row in RS])## 0 : id, 1 : label\n",
    "    RS_new = []\n",
    "    RS_labels = sc.parallelize(kmeans.labels_, n)\\\n",
    "        .map(lambda x : (x,1))\\\n",
    "        .reduceByKey(lambda a,b : a+b)\\\n",
    "        .filter(lambda x : x[1] == 1)\\\n",
    "        .map(lambda x : x[0]).collect()\n",
    "    CS_count = 0\n",
    "    RS_count = 0\n",
    "    for row, label in zip(RS, kmeans.labels_):\n",
    "        if label in RS_labels:\n",
    "            RS_count+=1\n",
    "            RS_new.append(row)\n",
    "        if label not in RS_labels:\n",
    "            CS_count+=1\n",
    "            CS[label] = CS.get(label, []) + [row]\n",
    "    #####   \n",
    "    N_CS = []\n",
    "    SUM_CS = []\n",
    "    SUMSQ_CS = []\n",
    "    for key in CS:\n",
    "        rows = CS[key]\n",
    "        num = 0\n",
    "        s = [0 for i in range(len(rows[0])-2)]\n",
    "        ssq = [0 for i in range(len(rows[0])-2)]\n",
    "        for row in rows:\n",
    "            num+=1\n",
    "            for i in range(len(rows[0])-2):\n",
    "                s[i]+=row[i+2]\n",
    "                ssq[i]+=row[i+2]**2\n",
    "        N_CS.append((key, num))\n",
    "        SUM_CS.append((key, s))\n",
    "        SUMSQ_CS.append((key, ssq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322312"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_data.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
