{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_down_support_threshold(basket_list, support, entire_size):\n",
    "    '''\n",
    "    calculate ps, scaled down support threshold\n",
    "    '''\n",
    "    partition_size = len(basket_list)\n",
    "    return math.ceil((partition_size / entire_size) * int(support))\n",
    "\n",
    "\n",
    "def count_singleton(baskets):\n",
    "    '''\n",
    "    generate dictionaray of singleton count\n",
    "    '''\n",
    "    count_num_dict = {}\n",
    "    for basket in baskets:\n",
    "        for item in basket:\n",
    "            count_num_dict[item] = count_num_dict.get(item, 0) + 1\n",
    "    return count_num_dict\n",
    "\n",
    "\n",
    "def get_candidate_singleton(count_dict, ps):\n",
    "    '''\n",
    "    Generate candidate from count dictionary\n",
    "    '''\n",
    "    candidate_list = []\n",
    "    for i in count_dict.keys():\n",
    "        if count_dict[i] >= ps:\n",
    "            candidate_list.append(i)\n",
    "\n",
    "    return candidate_list\n",
    "\n",
    "\n",
    "def get_candidate_pair(count_dict, ps):\n",
    "    '''\n",
    "    Generate candidate from count dictionary\n",
    "    '''\n",
    "    candidate_list = []\n",
    "    for i in count_dict.keys():\n",
    "        if count_dict[i] >= ps:\n",
    "            candidate_list.append(i)\n",
    "\n",
    "    return candidate_list\n",
    "\n",
    "\n",
    "def merge_basket_2d(baskets):\n",
    "    '''\n",
    "    partition to basket list\n",
    "    '''\n",
    "    a = list(baskets)\n",
    "    collected_basket = []\n",
    "    for i in a:\n",
    "        collected_basket += [i]\n",
    "    return collected_basket\n",
    "\n",
    "\n",
    "def generate_permutations(candidate_list, pair_size):\n",
    "    permu_list = []\n",
    "    if len(candidate_list) > 0:\n",
    "        for idx, itemset in enumerate(candidate_list[:-1]):\n",
    "            for itemset2 in candidate_list[idx + 1:]:\n",
    "                if list(itemset[:-1]) == list(itemset2[:-1]):\n",
    "                    candi = sorted(list(itemset) + [itemset2[-1]])\n",
    "                    if candi not in permu_list:\n",
    "                        check_list = [tuple(sorted(i)) for i in list(combinations(candi, pair_size - 1))]\n",
    "                        if set(check_list).issubset(candidate_list):\n",
    "                            permu_list.append(tuple(candi))\n",
    "\n",
    "    return permu_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def count_pairs(baskets, singleton_candidate):\n",
    "#     count_dict = {}\n",
    "#     for basket in baskets:\n",
    "#         for b1 in basket:\n",
    "#             for b2 in basket:\n",
    "#                 if b1 < b2 and b1 in singleton_candidate and b2 in singleton_candidate:\n",
    "#                             count_dict[(b1, b2)] = count_dict.get((b1, b2), 0) + 1\n",
    "\n",
    "#     return count_dict\n",
    "\n",
    "# def get_pair_candidate(baskets, singleton_candidate, ps):\n",
    "#     pair_candi_list = []\n",
    "#     pair_count = count_pairs(baskets, singleton_candidate)\n",
    "#     for candidate in pair_count.keys():\n",
    "#         if pair_count[candidate] > ps:\n",
    "#             pair_candi_list.append(candidate)\n",
    "#     return pair_candi_list\n",
    "\n",
    "\n",
    "def generate_pairs(singleton_candidate):\n",
    "    pair_list = []\n",
    "    for i in singleton_candidate:\n",
    "        for j in singleton_candidate:\n",
    "            if i < j:\n",
    "                pair_list.append((i, j))\n",
    "    return pair_list\n",
    "\n",
    "\n",
    "def pair_count(baskets, pair_list):\n",
    "    count_dict = {}\n",
    "    for pair in pair_list:\n",
    "        for basket in baskets:\n",
    "            if set(pair).issubset(set(basket)):\n",
    "                count_dict[pair] = count_dict.get(pair, 0) + 1\n",
    "    return count_dict\n",
    "\n",
    "\n",
    "def get_candidate_pair(count_dict, ps):\n",
    "    candidate_list = []\n",
    "    for pair in count_dict.keys():\n",
    "        if count_dict[pair] >= ps:\n",
    "            candidate_list.append(pair)\n",
    "\n",
    "    return candidate_list\n",
    "\n",
    "\n",
    "def apriori(partition, support, entire_size):\n",
    "    '''\n",
    "    perform pariori algorithm in the partition\n",
    "    with scaled down support threshold\n",
    "    '''\n",
    "    ## partition to baskets\n",
    "    baskets = merge_basket_2d(partition)\n",
    "\n",
    "    total_candidate = []\n",
    "\n",
    "    ## singleton\n",
    "    ps = scaled_down_support_threshold(baskets, support, entire_size)\n",
    "    singleton_candidate = get_candidate_singleton(count_singleton(baskets), ps)\n",
    "    baskets = [sorted(list(set(basket).intersection(set(singleton_candidate)))) for basket in baskets]\n",
    "    total_candidate += [(i,) for i in singleton_candidate]\n",
    "\n",
    "    ## pairs\n",
    "    pair_size = 2\n",
    "    pairs = generate_pairs(singleton_candidate)\n",
    "    counted_dict = pair_count(baskets, pairs)\n",
    "    pair_candidate = sorted(get_candidate_pair(counted_dict, ps))\n",
    "    total_candidate += pair_candidate\n",
    "\n",
    "    ##above triples\n",
    "    while len(pair_candidate) > 0:\n",
    "        pair_size += 1  ## pair_size = 3\n",
    "        pairs_to_be_counted = generate_permutations(pair_candidate, pair_size)\n",
    "        counted_dict = pair_count(baskets, pairs_to_be_counted)\n",
    "        pair_candidate = get_candidate_pair(counted_dict, ps)\n",
    "        total_candidate += pair_candidate\n",
    "\n",
    "\n",
    "    return total_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "from itertools import combinations\n",
    "\n",
    "from pyspark import SparkContext\n",
    "import os\n",
    "\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-dcbd679e0072>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduceByKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mcandidate_itemsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m## number of items in each partition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    814\u001b[0m         \"\"\"\n\u001b[1;32m    815\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jaeyoung/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    \n",
    "    support = 50\n",
    "    filter_threshold = 20\n",
    "    n =2\n",
    "    input_file = \"ta_feng_all_months_merged.csv\"\n",
    "    output_file = \"task2.txt\"\n",
    "    \n",
    "#     filter_threshold = int(sys.argv[1])\n",
    "#     support = int(sys.argv[2])  # support threshold\n",
    "#     input_file = sys.argv[3]\n",
    "#     output_file = sys.argv[4]\n",
    "#     n = 2  # partition_num\n",
    "    \n",
    "    \n",
    "    ## preprocessing\n",
    "    start_time = time.time()\n",
    "    textRDD = sc.textFile(input_file)\n",
    "    header = textRDD.first()  ## remove header\n",
    "    tmp = textRDD.filter(lambda x: x != header)\n",
    "\n",
    "    tmp = tmp.map(lambda x : [(x.split(\",\")[0][:-4]+x.split(\",\")[0][-2:])[1:-1] +'-' + str(int(x.split(\",\")[1][1:-1])), int(x.split(\",\")[5][1:-1])])\n",
    "    \n",
    "    fields = [\"DATE-CUSTOMER_ID\", \"PRODUCT_ID\"]\n",
    "    data = tmp.collect()\n",
    "    \n",
    "    with open('preprocessed_data.csv', 'w') as f: \n",
    "        write = csv.writer(f)     \n",
    "        write.writerow(fields) \n",
    "        write.writerows(data)\n",
    "\n",
    "    input_file = \"preprocessed_data.csv\"\n",
    "    \n",
    "    \n",
    "    ## Start Son\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "    textRDD = sc.textFile(input_file, n)\n",
    "    header = textRDD.first()  ## remove header\n",
    "    tmp = textRDD.filter(lambda x: x != header)\n",
    "\n",
    "    baskets = tmp.map(lambda x: x.split(\",\")).mapValues(lambda x: [x]).reduceByKey(lambda a, b: a + b) \\\n",
    "        .mapValues(lambda x: sorted(list(set(x)))).map(lambda x: x[1]).filter(lambda x: len(x)>filter_threshold)\n",
    "    basket_list = baskets.collect()\n",
    "        \n",
    "        \n",
    "\n",
    "    entire_size = len(basket_list)\n",
    "\n",
    "    num = baskets.mapPartitions(lambda x: [sum(1 for i in x)]).collect()  ## number of items in each partition\n",
    "\n",
    "    ## Phase 1\n",
    "\n",
    "    intermediate = baskets.mapPartitions(lambda x: apriori(x, s, entire_size)) \\\n",
    "        .map(lambda x: (x, 1)).reduceByKey(lambda a, b: a)\n",
    "\n",
    "    candidate_itemsets = list(set(intermediate.collect()))\n",
    "\n",
    "    num = tmp.mapPartitions(lambda x: [sum(1 for i in x)]).collect()  ## number of items in each partition\n",
    "    candidate_itemsets = sorted(candidate_itemsets, key=lambda x: (len(x[0]), x[0]))\n",
    "\n",
    "\n",
    "    ## Phase 2\n",
    "    \n",
    "    \n",
    "#     ### make baskets smaller\n",
    "#     singleton = []\n",
    "#     for i in candidate_itemsets:\n",
    "#         if len(i[0])==1:\n",
    "#             singleton.append(i[0][0])\n",
    "#     def shorter(baskets, singleton):\n",
    "#         baskets = [sorted(list(set(basket).intersection(set(singleton)))) for basket in baskets]\n",
    "#     baskets = baskets.map(lambda x : shorter(x, singleton))\n",
    "\n",
    "    def Map2(basket, candidate_itemsets):\n",
    "        answer_list = []\n",
    "        for candidate in candidate_itemsets:\n",
    "            if set(candidate[0]).issubset(set(basket)):\n",
    "                answer_list.append((candidate[0], 1))\n",
    "        size = len(answer_list)\n",
    "\n",
    "        return answer_list\n",
    "\n",
    "\n",
    "    freq_itemsets = baskets.map(lambda x: Map2(x, candidate_itemsets)).flatMap(lambda x: x).reduceByKey(\n",
    "        lambda a, b: a + b).filter(lambda x: x[1] >= int(support)).map(lambda x: x[0]).collect()\n",
    "\n",
    "    candidate_itemsets = [candidate[0] for candidate in candidate_itemsets]\n",
    "    freq_itemsets = sorted(freq_itemsets, key=lambda x: (len(x), x))\n",
    "\n",
    "    ## file write\n",
    "\n",
    "    file = open(output_file, \"w\")\n",
    "    file.write(\"Candidates:\")\n",
    "\n",
    "    ### format candidate\n",
    "    max_len = len(candidate_itemsets[-1])\n",
    "    answer_str = \"\"\n",
    "    answer_list = [\"\" for i in range(max_len + 1)]\n",
    "    for candidate in candidate_itemsets:\n",
    "        for i in range(1, max_len + 1):\n",
    "            if len(candidate) == i:\n",
    "                answer = \"('\"\n",
    "                for j in range(len(candidate)):\n",
    "                    answer += candidate[j]\n",
    "                    answer += \",\"\n",
    "                answer = answer[:-1] + \"')\"\n",
    "                answer_list[i] += answer\n",
    "                answer_list[i] += ','\n",
    "    for i in range(len(answer_list)):\n",
    "        answer_list[i] = answer_list[i][:-1]\n",
    "        answer_str += answer_list[i]\n",
    "        answer_str += '\\n\\n'\n",
    "    file.write(answer_str)\n",
    "\n",
    "    file.write(\"Frequent Itemsets:\")\n",
    "\n",
    "    ### format frequent itemsets\n",
    "    max_len = len(freq_itemsets[-1])\n",
    "    answer_str = \"\"\n",
    "    answer_list = [\"\" for i in range(max_len + 1)]\n",
    "    for candidate in freq_itemsets:\n",
    "        for i in range(1, max_len + 1):\n",
    "            if len(candidate) == i:\n",
    "                answer = \"('\"\n",
    "                for j in range(len(candidate)):\n",
    "                    answer += candidate[j]\n",
    "                    answer += \",\"\n",
    "                answer = answer[:-1] + \"')\"\n",
    "                answer_list[i] += answer\n",
    "                answer_list[i] += ','\n",
    "    for i in range(len(answer_list)):\n",
    "        answer_list[i] = answer_list[i][:-1]\n",
    "        answer_str +=answer_list[i]\n",
    "        answer_str +='\\n\\n'\n",
    "    file.write(answer_str)\n",
    "    file.close()\n",
    "    duration = (time.time() - start_time)\n",
    "    print(\"Duration: \", duration)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
